{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IjO7HW1ALp5i",
        "outputId": "b55d0937-7939-402c-9a2c-5fb6a5cee98e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting apache-tvm[tvmc]\n",
            "  Downloading apache_tvm-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (1.11.4)\n",
            "Collecting synr==0.6.0 (from apache-tvm[tvmc])\n",
            "  Downloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (4.11.0)\n",
            "Collecting ethos-u-vela==3.5.0 (from apache-tvm[tvmc])\n",
            "  Downloading ethos-u-vela-3.5.0.tar.gz (339 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.3/339.3 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (0.18.3)\n",
            "Collecting onnx (from apache-tvm[tvmc])\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxoptimizer (from apache-tvm[tvmc])\n",
            "  Downloading onnxoptimizer-0.3.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (678 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.1/678.1 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime (from apache-tvm[tvmc])\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paddlepaddle (from apache-tvm[tvmc])\n",
            "  Downloading paddlepaddle-2.6.1-cp310-cp310-manylinux1_x86_64.whl (125.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (2.15.0)\n",
            "Collecting tflite (from apache-tvm[tvmc])\n",
            "  Downloading tflite-2.10.0-py2.py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from apache-tvm[tvmc]) (0.18.0+cu121)\n",
            "Collecting xgboost<1.6.0,>=1.1.0 (from apache-tvm[tvmc])\n",
            "  Downloading xgboost-1.5.2-py3-none-manylinux2014_x86_64.whl (173.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.6/173.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers==1.12.0 (from ethos-u-vela==3.5.0->apache-tvm[tvmc])\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting numpy (from apache-tvm[tvmc])\n",
            "  Using cached numpy-1.21.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela==3.5.0->apache-tvm[tvmc]) (4.9.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->apache-tvm[tvmc]) (3.20.3)\n",
            "Collecting coloredlogs (from onnxruntime->apache-tvm[tvmc])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of onnxruntime to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnxruntime (from apache-tvm[tvmc])\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of onnxruntime to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.14.1-cp310-cp310-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.14.0-cp310-cp310-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnxruntime-1.13.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading onnxruntime-1.12.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime->apache-tvm[tvmc]) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->apache-tvm[tvmc]) (1.12)\n",
            "Collecting httpx (from paddlepaddle->apache-tvm[tvmc])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle->apache-tvm[tvmc]) (9.4.0)\n",
            "Collecting astor (from paddlepaddle->apache-tvm[tvmc])\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle->apache-tvm[tvmc]) (3.3.0)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy (from apache-tvm[tvmc])\n",
            "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (1.6.3)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow (from apache-tvm[tvmc])\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1 (from tensorflow->apache-tvm[tvmc])\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (1.64.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (3.9.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow->apache-tvm[tvmc])\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow->apache-tvm[tvmc])\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (18.1.1)\n",
            "Collecting tensorflow (from apache-tvm[tvmc])\n",
            "  Downloading tensorflow-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (1.16.0)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow->apache-tvm[tvmc])\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (0.37.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow->apache-tvm[tvmc])\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->apache-tvm[tvmc]) (1.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->apache-tvm[tvmc]) (3.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->apache-tvm[tvmc]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->apache-tvm[tvmc]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->apache-tvm[tvmc]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->apache-tvm[tvmc])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->apache-tvm[tvmc]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->apache-tvm[tvmc])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->apache-tvm[tvmc]) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc])\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (3.6)\n",
            "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow->apache-tvm[tvmc])\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc])\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc])\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (3.0.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->apache-tvm[tvmc])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle->apache-tvm[tvmc]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle->apache-tvm[tvmc]) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->paddlepaddle->apache-tvm[tvmc])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle->apache-tvm[tvmc]) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle->apache-tvm[tvmc]) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->paddlepaddle->apache-tvm[tvmc])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->apache-tvm[tvmc]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->apache-tvm[tvmc]) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle->apache-tvm[tvmc]) (1.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->apache-tvm[tvmc]) (3.2.2)\n",
            "Building wheels for collected packages: ethos-u-vela\n",
            "  Building wheel for ethos-u-vela (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ethos-u-vela: filename=ethos_u_vela-3.5.0-cp310-cp310-linux_x86_64.whl size=435803 sha256=a3aeeb9d1fe195df96867901cf08801abb2690fdba66a2f17cf44766c45b4a32\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/d4/d0/49e0c28917caeff2dbf60774b83300a7a36cb5f8fdb05b2199\n",
            "Successfully built ethos-u-vela\n",
            "Installing collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, synr, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, humanfriendly, h11, gast, astor, tflite, scipy, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, keras-preprocessing, httpcore, ethos-u-vela, coloredlogs, xgboost, onnxruntime, onnxoptimizer, nvidia-cusolver-cu12, httpx, google-auth-oauthlib, apache-tvm, tensorboard, paddlepaddle, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.21.3 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.21.3 which is incompatible.\n",
            "flax 0.8.3 requires numpy>=1.22, but you have numpy 1.21.3 which is incompatible.\n",
            "jax 0.4.26 requires numpy>=1.22, but you have numpy 1.21.3 which is incompatible.\n",
            "jaxlib 0.4.26+cuda12.cudnn89 requires numpy>=1.22, but you have numpy 1.21.3 which is incompatible.\n",
            "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 1.21.3 which is incompatible.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.21.3 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.21.3 which is incompatible.\n",
            "pywavelets 1.6.0 requires numpy<3,>=1.22.4, but you have numpy 1.21.3 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.21.3 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.21.3 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.9.0 which is incompatible.\n",
            "xarray-einstats 0.7.0 requires numpy>=1.22, but you have numpy 1.21.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-tvm-0.11.1 astor-0.8.1 coloredlogs-15.0.1 ethos-u-vela-3.5.0 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 humanfriendly-10.0 keras-2.9.0 keras-preprocessing-1.1.2 numpy-1.21.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 onnx-1.16.1 onnxoptimizer-0.3.13 onnxruntime-1.12.1 paddlepaddle-2.6.1 scipy-1.10.1 synr-0.6.0 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0 tflite-2.10.0 xgboost-1.5.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "5080473594964be4baa5021f0636ed46",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install  apache-tvm[tvmc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1Pi6lXENbBc",
        "outputId": "aa3b61d0-358b-4be2-abf4-d6574a3ef025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.11.1\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "print(tvm.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6okl6L8oNgJ-"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CGwy24ScQH7v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def images_to_npz(directory, output_file):\n",
        "    # List to hold image data\n",
        "    images = []\n",
        "    # Get all JPEG files from the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.jpg'):\n",
        "            # Path to the image file\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            # Open the image file\n",
        "            with Image.open(filepath) as img:\n",
        "                # Convert image to numpy array\n",
        "                img_array = np.array(img)\n",
        "                # Append to list of images\n",
        "                images.append(img_array)\n",
        "\n",
        "    # Save all images in a single .npz file\n",
        "    np.savez_compressed(output_file, *images)\n",
        "\n",
        "# Example usage\n",
        "images_to_npz('/home/manoj/TVM/TVMenv/TVM/', 'mnist_images.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BgxG3C73XB7K"
      },
      "outputs": [],
      "source": [
        "#array= np.load('/content/sample_data/digit.npy')\n",
        "#np.savez('digit.npz', arr_0= array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "h5BEHpe4ZV4-",
        "outputId": "c57e4666-86c6-4c36-82f9-55a96d958331"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'arr_0 is not a file in the archive'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fce56aa6d3ae>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/digit.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'arr_0 is not a file in the archive'"
          ]
        }
      ],
      "source": [
        "#data= np.load('/content/sample_data/digit.npz')\n",
        "#print(data['arr_0'])\n",
        "#data.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkl_Lg_3UV7b",
        "outputId": "c6d3c995-6c8e-4c98-e38d-b73435e414b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arrays in NPZ file: ['arr_0']\n",
            "Contents of arr_0:\n",
            "[[  0   0   0   0   0   0   0   0   4   0   0   0   3   0   0   2   0   0\n",
            "    0   5   2   0   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   8  12   4   0   0   5   1   0\n",
            "    2   5   5   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   7   0   0   5   0   0   2   0   7   4\n",
            "    0   0   0   4   4   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  11   0   0   0   0   4   6   0   1   2\n",
            "    0   0   0   2   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   9  10   1   0   2   2   0   1\n",
            "    7   7   5   4   3   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   3   1   0\n",
            "    0   0   0   0   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  18  14  28  81  96  81  88  91  83\n",
            "   81  81  61  25   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  12  82 125 172 246 255 241 255 246 244\n",
            "  255 255 220 132  50  10   0   0   0   0]\n",
            " [  0   8   0   0  12   0   0  84 161 236 251 255 250 255 249 246 255 237\n",
            "  250 247 255 235 212  55   0   0  11   6]\n",
            " [  0   0   1   5   2   0  19 121 255 244 250 250 233 242 255 255 231 252\n",
            "  255 251 234 255 252  85  16   3   0   0]\n",
            " [ 11   0   0   8   0   0 115 250 247 230 255 211 219 212 203 179   4  13\n",
            "    0   5  59 238 252  77   0   0   0   3]\n",
            " [  0   4   2   0   7  66 233 253 255 255 206   0   2   6   0   0   0   8\n",
            "    0   6  31 195 253 142  24  14   3   3]\n",
            " [  0   4   2   2   4  30 245 255 241 251 200   0   3   5   0   0  11   9\n",
            "    0   0   0  90 235 255  27   0   3   0]\n",
            " [ 11   0   0   5   0  42 240 255 142  95  82   6   0   0   6   4   1   0\n",
            "    0   9   9  30 165 238  59   0   0   0]\n",
            " [  0   6   0   0   8 216 255 135  14   0   0   5   0   0   4   0   3   7\n",
            "    0   0   0   0 139 255 203  19   9   0]\n",
            " [  0   1   4   0   3 255 223 111   0  23   0   0   0  10   0   0   0  12\n",
            "    0   0   2  22 142 250 247   3   0   1]\n",
            " [  0   3   0   0   0 255 148  13   3   0   0   8   0   0   2   0   0   2\n",
            "    5   0  97 149 235 255 168  17   0   0]\n",
            " [  6   0   3   9   3 240 227  52   0   6   5   1   0   0  14   0   0   0\n",
            "  104 128 245 241 255 244  60   0   0  10]\n",
            " [  0   0   0   0   0 255 254 205  52  19   0   0   0  29 116 173 172 189\n",
            "  208 239 255 255 245 143   4   0  13   2]\n",
            " [  9   9   0   0  27 242 250 250 224 207 201 223 214 200 234 255 252 229\n",
            "  253 247 252 254 129  23   8   9  13   0]\n",
            " [  0   1   7   0   0  39 252 255 241 254 254 255 251 255 255 250 255 251\n",
            "  255 223 182   0   0   2   0   2   1   0]\n",
            " [ 16   9   0   0  12  21 177 204 255 255 241 249 244 236 247 238 154 169\n",
            "  160  10  11   8   7   0   0   0   0   0]\n",
            " [  0   0   1   3   1   9   0  58 114 112 163 253 253 172 124 105   3  14\n",
            "    0   7   1   0   0   1   5   6   2   1]\n",
            " [ 11   0   0   5   0   0   4   0   7   0  17  80  78  23   4   0   9   0\n",
            "    3   4   0   0   7   0   0   0   0   5]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "shape of the input file 'arr_0 : (28, 28)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the NPZ file\n",
        "data = np.load('/home/manoj/TVM/TVMenv/TVM/mnist_images.npz', allow_pickle=True)\n",
        "input_tensor = data['arr_0']\n",
        "\n",
        "# Now, prepare a dictionary with the correct input name expected by the model\n",
        "model_inputs = {'data': input_tensor}\n",
        "\n",
        "\n",
        "# List all arrays in the file\n",
        "print(\"Arrays in NPZ file:\", data.files)\n",
        "\n",
        "\n",
        "# Access and print each array\n",
        "for file in data.files:\n",
        "    print(f\"Contents of {file}:\")\n",
        "    print(data[file])\n",
        "    print(f\"shape of the input file '{file} : {data[file].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4wnhuuzZmY6",
        "outputId": "eb4536f8-e2cc-4dd5-cb2e-f971f10b7250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New shape of arr_0: (1, 1, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from PIL import Image\n",
        "\n",
        "def prepare_image_array(array):\n",
        "    # Convert array to Image for resizing\n",
        "    image = Image.fromarray((array * 255).astype(np.uint8))  # Scale back to [0, 255] and convert to uint8\n",
        "    #image = image.resize((224, 224))  # Resize image if necessary\n",
        "    #array_resized = np.array(image).astype(np.float32) / 255.0  # Convert back to float32 and scale to [0, 1]\n",
        "\n",
        "    image= image.convert('L')\n",
        "    # Reshape to [ 28, 28]\n",
        "    image= image.resize((28,28))\n",
        "    array_resized = np.array(image).astype(np.float32) / 255.0\n",
        "\n",
        "    # Add a batch dimension to make it [1, 1, 28, 28]\n",
        "    array_resized = array_resized[np.newaxis, :]\n",
        "    array_resized = array_resized[np.newaxis, :]\n",
        "    return array_resized\n",
        "# Assuming 'data' is your loaded npz file\n",
        "data = np.load(\"/home/manoj/TVM/TVMenv/TVM/mnist_images.npz\")\n",
        "\n",
        "# Dictionary to store modified arrays\n",
        "modified_arrays = {}\n",
        "# Process each image\n",
        "for key in data.files:\n",
        "    array = data[key]\n",
        "    array_prepared = prepare_image_array(array)\n",
        "    modified_arrays[key] = array_prepared\n",
        "    print(f\"New shape of {key}:\", array_prepared.shape)\n",
        "\n",
        "# Save the modified arrays back to an NPZ file\n",
        "np.savez_compressed(\"/home/manoj/TVM/TVMenv/TVM/modified_output_images_mnist.npz\", **modified_arrays)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New shape of arr_0: (1, 3, 224, 224)\n"
          ]
        }
      ],
      "source": [
        "#for resnet test images\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def prepare_image_array(array):\n",
        "    # Convert array to Image for resizing\n",
        "    image = Image.fromarray((array * 255).astype(np.uint8))  # Scale back to [0, 255] and convert to uint8\n",
        "    image = image.resize((224, 224))  # Resize image if necessary\n",
        "    array_resized = np.array(image).astype(np.float32) / 255.0  # Convert back to float32 and scale to [0, 1]\n",
        "\n",
        "    # Reshape to [3, 224, 224]\n",
        "    array_resized = array_resized.transpose((2, 0, 1))\n",
        "\n",
        "    # Add a batch dimension to make it [1, 3, 224, 224]\n",
        "    array_resized = array_resized[np.newaxis, :]\n",
        "    return array_resized\n",
        "\n",
        "# Assuming 'data' is your loaded npz file\n",
        "data = np.load(\"/home/manoj/TVM/TVMenv/TVM/mnist_images.npz\")\n",
        "\n",
        "# Dictionary to store modified arrays\n",
        "modified_arrays = {}\n",
        "\n",
        "# Process each image and store in dictionary\n",
        "for key in data.files:\n",
        "    array = data[key]\n",
        "    array_prepared = prepare_image_array(array)\n",
        "    modified_arrays[key] = array_prepared  # Store the reshaped array\n",
        "    print(f\"New shape of {key}:\", array_prepared.shape)\n",
        "\n",
        "# Save the modified arrays back to an NPZ file\n",
        "np.savez_compressed(\"/home/manoj/TVM/TVMenv/TVM/modified_output_images2.npz\", **modified_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYxjMeZmQJbR",
        "outputId": "50891204-8db6-4b82-8aae-f386481d1715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i32QvNBGNkYH"
      },
      "outputs": [],
      "source": [
        "import tvm\n",
        "from tvm.driver import tvmc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vXRECP1LNuTq"
      },
      "outputs": [],
      "source": [
        "#load\n",
        "model = tvmc.load(\"/home/manoj/TVM/TVMenv/TVM/mnist-1.onnx\", shape_dict={'Input73' : [1, 1, 28, 28]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvqu1mRDItVT",
        "outputId": "3048a5c0-7d77-4070-8a46-2799676fe7b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def @main(%Input73: Tensor[(1, 1, 28, 28), float32] /* ty=Tensor[(1, 1, 28, 28), float32] */) -> Tensor[(1, 10), float32] {\n",
            "  %0 = divide(%Input73, 255f /* ty=float32 */) /* ty=Tensor[(1, 1, 28, 28), float32] */;\n",
            "  %1 = nn.pad(%0, 0f /* ty=float32 */, pad_width=[[0i64, 0i64], [0i64, 0i64], [2i64, 2i64], [2i64, 2i64]]) /* ty=Tensor[(1, 1, 32, 32), float32] */;\n",
            "  %2 = nn.conv2d(%1, meta[relay.Constant][0] /* ty=Tensor[(8, 1, 5, 5), float32] */, padding=[0, 0, 0, 0], channels=8, kernel_size=[5, 5]) /* ty=Tensor[(1, 8, 28, 28), float32] */;\n",
            "  %3 = add(%2, meta[relay.Constant][1] /* ty=Tensor[(8, 1, 1), float32] */) /* ty=Tensor[(1, 8, 28, 28), float32] */;\n",
            "  %4 = nn.relu(%3) /* ty=Tensor[(1, 8, 28, 28), float32] */;\n",
            "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 8, 14, 14), float32] */;\n",
            "  %6 = nn.pad(%5, 0f /* ty=float32 */, pad_width=[[0i64, 0i64], [0i64, 0i64], [2i64, 2i64], [2i64, 2i64]]) /* ty=Tensor[(1, 8, 18, 18), float32] */;\n",
            "  %7 = nn.conv2d(%6, meta[relay.Constant][2] /* ty=Tensor[(16, 8, 5, 5), float32] */, padding=[0, 0, 0, 0], channels=16, kernel_size=[5, 5]) /* ty=Tensor[(1, 16, 14, 14), float32] */;\n",
            "  %8 = add(%7, meta[relay.Constant][3] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 14, 14), float32] */;\n",
            "  %9 = nn.relu(%8) /* ty=Tensor[(1, 16, 14, 14), float32] */;\n",
            "  %10 = nn.max_pool2d(%9, pool_size=[3, 3], strides=[3, 3], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 16, 4, 4), float32] */;\n",
            "  %11 = reshape(%10, newshape=[1, 256]) /* ty=Tensor[(1, 256), float32] */;\n",
            "  %12 = nn.dense(%11, meta[relay.Constant][4] /* ty=Tensor[(10, 256), float32] */, units=None, out_dtype=\"float32\") /* ty=Tensor[(1, 10), float32] */;\n",
            "  add(%12, meta[relay.Constant][5] /* ty=Tensor[(1, 10), float32] */) /* ty=Tensor[(1, 10), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naGT8ySyjSnu",
        "outputId": "31f9d416-578d-4dd4-d66b-29eba57c694e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New shape of arr_0: (1, 3, 224, 224)\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'data' is your loaded npz file\n",
        "data = np.load(\"/home/manoj/TVM/TVMenv/TVM/output_images.npz\")\n",
        "\n",
        "# Dictionary to store modified arrays\n",
        "modified_arrays = {}\n",
        "\n",
        "# Process each image and store in dictionary\n",
        "for key in data.files:\n",
        "    array = data[key]\n",
        "    array_prepared = prepare_image_array(array)\n",
        "    modified_arrays[key] = array_prepared  # Store the reshaped array\n",
        "    print(f\"New shape of {key}:\", array_prepared.shape)\n",
        "\n",
        "# Save the modified arrays back to an NPZ file\n",
        "np.savez_compressed(\"/home/manoj/TVM/TVMenv/TVM/modified_output_images.npz\", **modified_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2xUAFCtPNxDY"
      },
      "outputs": [],
      "source": [
        "data= np.load(\"/home/manoj/TVM/TVMenv/TVM/modified_output_images_mnist.npz\")\n",
        "# Extract the array stored under the key 'arr_0'\n",
        "inputs = data['arr_0']  # This is the correct assignment\n",
        "\n",
        "# Prepare the input dictionary expected by TVMC\n",
        "# Replace 'arr_0' with the correct tensor name 'data'\n",
        "minputs = {'Input73': inputs}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "NT1uhbeFONpm",
        "outputId": "b834c45a-e668-4b71-8a9e-8f5cbf6d6e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Task  1/ 4]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/2500) | 0.00 s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Exception in thread Thread-18 (_check):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "Thread-1 (_listen_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    _threading_Thread_run(self)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/measure/measure_methods.py\", line 831, in _check\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/server.py\", line 237, in _listen_loop\n",
            "    raise exc\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/server.py\", line 222, in _listen_loop\n",
            "    raise RuntimeError(\"%s is not RPC Tracker\" % str(tracker_addr))\n",
            "RuntimeError: ('127.0.0.1', 9000) is not RPC Tracker\n",
            "    remote = request_remote(device_key, host, port, priority)\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/measure/measure_methods.py\", line 797, in request_remote\n",
            "    tracker = _rpc.connect_tracker(host, port)\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/client.py\", line 545, in connect_tracker\n",
            "    return TrackerSession((url, port))\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/client.py\", line 294, in __init__\n",
            "    self._connect()\n",
            "  File \"/home/manoj/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/client.py\", line 304, in _connect\n",
            "    raise RuntimeError(\"%s is not RPC Tracker\" % str(self._addr))\n",
            "RuntimeError: ('127.0.0.1', 9000) is not RPC Tracker\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "('127.0.0.1', 9000) is not RPC Tracker",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#tune\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtvmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllvm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuning_records\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtuning_logs.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/driver/tvmc/autotuner.py:498\u001b[0m, in \u001b[0;36mtune_model\u001b[0;34m(tvmc_model, target, tuning_records, prior_records, enable_autoscheduler, rpc_key, hostname, port, trials, target_host, tuner, min_repeat_ms, early_stopping, desired_layout, timeout, repeat, number, parallel, hardware_params, include_simple_tasks, log_estimated_latency, additional_target_options)\u001b[0m\n\u001b[1;32m    487\u001b[0m     tuning_options \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner\u001b[39m\u001b[38;5;124m\"\u001b[39m: tuner,\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrials\u001b[39m\u001b[38;5;124m\"\u001b[39m: trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuning_records\u001b[39m\u001b[38;5;124m\"\u001b[39m: prior_records,\n\u001b[1;32m    495\u001b[0m     }\n\u001b[1;32m    496\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutotuning with configuration: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tuning_options)\n\u001b[0;32m--> 498\u001b[0m     \u001b[43mtune_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuning_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtuning_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuning_records\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/driver/tvmc/autotuner.py:699\u001b[0m, in \u001b[0;36mtune_tasks\u001b[0;34m(tasks, log_file, measure_option, tuner, trials, early_stopping, tuning_records)\u001b[0m\n\u001b[1;32m    696\u001b[0m     tuner_obj\u001b[38;5;241m.\u001b[39mload_history(autotvm\u001b[38;5;241m.\u001b[39mrecord\u001b[38;5;241m.\u001b[39mload_from_file(tuning_records))\n\u001b[1;32m    697\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded history in \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m sec(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m--> 699\u001b[0m \u001b[43mtuner_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtsk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_space\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeasure_option\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeasure_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautotvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautotvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/tuner/xgboost_tuner.py:105\u001b[0m, in \u001b[0;36mXGBTuner.tune\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# pylint: disable=arguments-differ\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXGBTuner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# manually close pool to avoid multiprocessing issues\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost_model\u001b[38;5;241m.\u001b[39m_close_pool()\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/tuner/tuner.py:114\u001b[0m, in \u001b[0;36mTuner.tune\u001b[0;34m(self, n_trial, measure_option, early_stopping, callbacks, si_prefix)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_trial, measure_option, early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m(), si_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Begin tuning\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m        One of tvm.autotvm.utils.SI_PREFIXES. The SI prefix to use when reporting FLOPS.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     measure_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_measure_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasure_option\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     n_parallel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(measure_batch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_parallel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    116\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m early_stopping \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1e9\u001b[39m\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/measure/measure.py:282\u001b[0m, in \u001b[0;36mcreate_measure_batch\u001b[0;34m(task, option)\u001b[0m\n\u001b[1;32m    279\u001b[0m builder \u001b[38;5;241m=\u001b[39m option[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    280\u001b[0m runner \u001b[38;5;241m=\u001b[39m option[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunner\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 282\u001b[0m attach_objects \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# feed device related information from runner to builder\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# (e.g. max shared memory for validity checking)\u001b[39;00m\n\u001b[1;32m    286\u001b[0m build_kwargs \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39mget_build_kwargs()\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/measure/measure_methods.py:494\u001b[0m, in \u001b[0;36mLocalRunner.set_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m127.0.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mport\n\u001b[0;32m--> 494\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLocalRunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m server, tracker\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/measure/measure_methods.py:322\u001b[0m, in \u001b[0;36mRPCRunner.set_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, task):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcheck_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    323\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet devices for measurement successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/measure/measure_methods.py:843\u001b[0m, in \u001b[0;36mcheck_remote\u001b[0;34m(target, device_key, host, port, priority, timeout)\u001b[0m\n\u001b[1;32m    840\u001b[0m t\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    841\u001b[0m t\u001b[38;5;241m.\u001b[39mjoin(timeout)\n\u001b[0;32m--> 843\u001b[0m remote \u001b[38;5;241m=\u001b[39m \u001b[43mrequest_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m dev \u001b[38;5;241m=\u001b[39m remote\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28mstr\u001b[39m(target))\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dev\u001b[38;5;241m.\u001b[39mexist\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/autotvm/measure/measure_methods.py:797\u001b[0m, in \u001b[0;36mrequest_remote\u001b[0;34m(device_key, host, port, priority, timeout)\u001b[0m\n\u001b[1;32m    794\u001b[0m host \u001b[38;5;241m=\u001b[39m host \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTVM_TRACKER_HOST\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    795\u001b[0m port \u001b[38;5;241m=\u001b[39m port \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTVM_TRACKER_PORT\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 797\u001b[0m tracker \u001b[38;5;241m=\u001b[39m \u001b[43m_rpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_tracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m remote \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mrequest(device_key, priority\u001b[38;5;241m=\u001b[39mpriority, session_timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/client.py:545\u001b[0m, in \u001b[0;36mconnect_tracker\u001b[0;34m(url, port)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect_tracker\u001b[39m(url, port):\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Connect to a RPC tracker\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m        The connected tracker session.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTrackerSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/client.py:294\u001b[0m, in \u001b[0;36mTrackerSession.__init__\u001b[0;34m(self, addr)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_addr \u001b[38;5;241m=\u001b[39m addr\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/TVM/TVMenv/lib/python3.10/site-packages/tvm/rpc/client.py:304\u001b[0m, in \u001b[0;36mTrackerSession._connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m magic \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i\u001b[39m\u001b[38;5;124m\"\u001b[39m, base\u001b[38;5;241m.\u001b[39mrecvall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock, \u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m base\u001b[38;5;241m.\u001b[39mRPC_TRACKER_MAGIC:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not RPC Tracker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_addr))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: ('127.0.0.1', 9000) is not RPC Tracker"
          ]
        }
      ],
      "source": [
        "#tune\n",
        "tvmc.tune(model,target=\"llvm\", number=2, tuning_records=\"tuning_logs.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mWRHyBq4OYVT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        }
      ],
      "source": [
        "#compile\n",
        "compiled_model= tvmc.compile(model, tuning_records=\"tuning_logs.json\", target=\"llvm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mfqkUzFOotB",
        "outputId": "0aea0fc3-b0f9-4186-9ec6-6c72e228158e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-29 11:27:48.910 INFO load_module /tmp/tmpnp5g1_tl/mod.so\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "Output Names:\n",
            " ['output_0']\n"
          ]
        }
      ],
      "source": [
        "#Run\n",
        "model_output= tvmc.run(compiled_model, device=\"cpu\", inputs=minputs, profile=False)\n",
        "print(model_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XZOx0OuHO1_2"
      },
      "outputs": [],
      "source": [
        "model_output.save(\"/home/manoj/TVM/TVMenv/TVM/output_mnist1.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDyoSpkXm9Wg",
        "outputId": "c54c7e90-d624-4ba3-b4fe-522283484341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arrays in the NPZ file and their previews:\n",
            "Key: output_0\n",
            "Shape: (1, 10)\n",
            "Data Preview (first few items): [-0.04485603  0.00779166  0.06810082  0.02999374 -0.12640963  0.14021875\n",
            " -0.0552849  -0.04938382  0.08432205 -0.05454041]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the NPZ file\n",
        "data = np.load('/home/manoj/TVM/TVMenv/TVM/output3.npz')\n",
        "\n",
        "# List all arrays in the file and print their shape and a small preview\n",
        "print(\"Arrays in the NPZ file and their previews:\")\n",
        "for key in data.files:\n",
        "    print(f\"Key: {key}\")\n",
        "    print(\"Shape:\", data[key].shape)\n",
        "    print(\"Data Preview (first few items):\", data[key].flatten()[:10])  # Flatten and show first 10 items\n",
        "    print()  # Add a newline for better readability between entries\n",
        "\n",
        "# Close the file after processing\n",
        "data.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-5 imagenet classes:\n",
            "class='n02124075 Egyptian cat' with probability=0.44\n",
            "class='n02123159 tiger cat' with probability=0.26\n",
            "class='n02123045 tabby, tabby cat' with probability=0.22\n",
            "class='n02129604 tiger, Panthera tigris' with probability=0.01\n",
            "class='n04040759 radiator' with probability=0.00\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from scipy.special import softmax\n",
        "from tvm.contrib.download import download_testdata\n",
        "\n",
        "# Download a list of labels\n",
        "labels_url = \"https://s3.amazonaws.com/onnx-model-zoo/synset.txt\"\n",
        "labels_path = download_testdata(labels_url, \"synset.txt\", module=\"data\")\n",
        "\n",
        "with open(labels_path, \"r\") as f:\n",
        "    labels = [l.rstrip() for l in f]\n",
        "\n",
        "output_file = \"/home/manoj/TVM/TVMenv/TVM/output_resnet.npz\"\n",
        "\n",
        "print(\"Top-5 imagenet classes:\")\n",
        "# Open the output and read the output tensor\n",
        "if os.path.exists(output_file):\n",
        "    with np.load(output_file) as data:\n",
        "        scores = softmax(data[\"output_0\"])\n",
        "        scores = np.squeeze(scores)\n",
        "        ranks = np.argsort(scores)[::-1]\n",
        "\n",
        "        for rank in ranks[:5]:\n",
        "            print(f\"class='{labels[rank]}' with probability={scores[rank]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-5 MNIST classes:\n",
            "class='Five' with probability=0.11\n",
            "class='Eight' with probability=0.11\n",
            "class='Two' with probability=0.11\n",
            "class='Three' with probability=0.10\n",
            "class='One' with probability=0.10\n"
          ]
        }
      ],
      "source": [
        "#for mnist dataset\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Define the MNIST labels\n",
        "labels = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
        "\n",
        "output_file = \"/home/manoj/TVM/TVMenv/TVM/output_mnist1.npz\"\n",
        "\n",
        "print(\"Top-5 MNIST classes:\")\n",
        "# Open the output and read the output tensor\n",
        "if os.path.exists(output_file):\n",
        "    with np.load(output_file) as data:\n",
        "        scores = softmax(data[\"output_0\"])\n",
        "        scores = np.squeeze(scores)\n",
        "        ranks = np.argsort(scores)[::-1]\n",
        "\n",
        "        for rank in ranks[:5]:\n",
        "            print(f\"class='{labels[rank]}' with probability={scores[rank]:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
